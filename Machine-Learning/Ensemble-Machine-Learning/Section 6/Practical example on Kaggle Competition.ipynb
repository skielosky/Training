{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses scripts from https://github.com/martin-1992/stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arish/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arish/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8742985409652076"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from process import coreProcess\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from clfParams import paramDict\n",
    "\n",
    "\n",
    "class baseClassifier(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "\n",
    "##############################################################\n",
    "def get_oof(clf, X_train, y_train, X_test):\n",
    "    oof_train = np.zeros((n_train, ))\n",
    "    oof_test = np.zeros((n_test, ))\n",
    "    # n_folds * n_test,\n",
    "    oof_test_skf = np.empty((n_folds, n_test))\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(kf):\n",
    "        kf_x_train = X_train[train_idx]\n",
    "        kf_y_train = y_train[train_idx]\n",
    "        kf_x_val = X_train[val_idx]\n",
    "\n",
    "        clf.train(kf_x_train, kf_y_train)\n",
    "        oof_train[val_idx] = clf.predict(kf_x_val)\n",
    "        oof_test_skf[i, :] = clf.predict(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def accuracy(pred_y, true_y):\n",
    "    return np.sum((pred_y == y_train).astype(float)) / len(true_y)\n",
    "\n",
    "\n",
    "df, train_idx, test_idx = coreProcess()\n",
    "\n",
    "n_train = len(train_idx)\n",
    "n_test = len(test_idx)\n",
    "seed = 0\n",
    "n_folds = 5\n",
    "kf = KFold(n_train, n_folds=n_folds, random_state=seed)\n",
    "\n",
    "param_dict = paramDict()\n",
    "\n",
    "rf = baseClassifier(clf=RandomForestClassifier, seed=seed, params=param_dict['rf_params'])\n",
    "et = baseClassifier(clf=ExtraTreesClassifier, seed=seed, params=param_dict['et_params'])\n",
    "ada = baseClassifier(clf=AdaBoostClassifier, seed=seed, params=param_dict['ada_params'])\n",
    "gb = baseClassifier(clf=GradientBoostingClassifier, seed=seed, params=param_dict['gb_params'])\n",
    "svc = baseClassifier(clf=SVC, seed=seed, params=param_dict['svc_params'])\n",
    "\n",
    "feats_not_use = ['Name', 'Cabin', 'PassengerId', 'Ticket',\n",
    "                 'Ticket_prefix', 'Survived']\n",
    "feats_in_use = [col for col in df.columns if col not in feats_not_use]\n",
    "\n",
    "use_df = df[feats_in_use]\n",
    "y_train = df.loc[train_idx, 'Survived'].ravel()\n",
    "X_train = use_df.loc[train_idx, :]\n",
    "X_train = X_train.values\n",
    "X_test = use_df.loc[test_idx, :].values\n",
    "\n",
    "et_oof_train, et_oof_test = get_oof(et, X_train, y_train, X_test)\n",
    "rf_oof_train, rf_oof_test = get_oof(rf, X_train, y_train, X_test)\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X_train, y_train, X_test)\n",
    "gb_oof_train, gb_oof_test = get_oof(gb, X_train, y_train, X_test)\n",
    "svc_oof_train, svc_oof_test = get_oof(svc, X_train, y_train, X_test)\n",
    "\n",
    "level1_train = np.concatenate((et_oof_train, rf_oof_train, ada_oof_train,\n",
    "                               gb_oof_train, svc_oof_train), axis=1)\n",
    "level1_test = np.concatenate((et_oof_test, rf_oof_test, ada_oof_test,\n",
    "                              gb_oof_test, svc_oof_test), axis=1)\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "            n_estimators = 2000,\n",
    "            max_depth = 4,\n",
    "            min_child_weight = 2,\n",
    "            gamma = 0.9,\n",
    "            subsample = 0.8,\n",
    "            colsample_bytree = 0.8,\n",
    "            objective = 'binary:logistic',\n",
    "            nthread = -1,\n",
    "            scale_pos_weight = 1)\n",
    "\n",
    "clf.fit(level1_train, y_train)\n",
    "pred_y = clf.predict(level1_test)\n",
    "\n",
    "\n",
    "accuracy(clf.predict(level1_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
